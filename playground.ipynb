{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#General preprocessing/ plotting/ format switching functions\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "\n",
    "def write_tiff_data_into_tensor(path):\n",
    "    inputTensor = []\n",
    "    files = [file for file in os.listdir(path) if file[-4:]=='.tif']\n",
    "    files = sorted(files, key=lambda x:int(x.partition('126054_')[2].partition('_')[0]))\n",
    "    for file in files:\n",
    "        image = Image.open(os.path.join(path, file))\n",
    "        image = np.asarray(image)\n",
    "        inputTensor.append(image)\n",
    "    inputTensor = np.asarray(inputTensor)\n",
    "    return inputTensor\n",
    "    \n",
    "def write_tiff_data_into_text_file(pathIn='data\\\\Tiff_Image', pathOut='data\\\\text_data'):\n",
    "    labels_tensor = []\n",
    "    files = [file for file in os.listdir(path) if file[-4:]=='.tif']\n",
    "    files = sorted(files, key=lambda x:int(x.partition('126054_')[2].partition('_')[0]))\n",
    "    for file in files:\n",
    "        label = Image.open(os.path.join(path, file))\n",
    "        label = np.asarray(label)\n",
    "        labels_tensor.append(label)\n",
    "    labels_tensor = np.asarray(labels_tensor)\n",
    "    for name, label in zip(files, labels_tensor):\n",
    "        c=0\n",
    "        f = open(os.path.join(pathOut,name[:-4]+'.txt'), '+w')\n",
    "        for line in label:\n",
    "            for sample in line:\n",
    "                f.write('{}'.format(sample))\n",
    "            c=c+1\n",
    "            if c < label.shape[0]: #i hate EOF new line\n",
    "                f.write('\\n')\n",
    "        f.close()\n",
    "\n",
    "def write_text_data_into_tensor(path):\n",
    "    inputTensor = []\n",
    "    files = [file for file in os.listdir(path) if file[-4:]=='.txt']\n",
    "    files = sorted(files, key=lambda x:int(x.partition('126054_')[2].partition('_')[0]))\n",
    "    for file in files:\n",
    "        with open(os.path.join(path, file), 'r', encoding='utf-8') as f:\n",
    "            lines = f.read().split('\\n')\n",
    "        dataPoint = []\n",
    "        for line in lines:\n",
    "            tmp = []\n",
    "            for value in line:\n",
    "                tmp.append(int(value))\n",
    "            dataPoint.append(tmp)\n",
    "        dataPoint = np.asarray(dataPoint, dtype=np.uint8)\n",
    "        inputTensor.append(dataPoint)\n",
    "    inputTensor = np.asarray(inputTensor, dtype = np.uint8)\n",
    "    return inputTensor\n",
    "\n",
    "def write_tensor_into_images(path, inputTensor):\n",
    "    for c,i in enumerate(inputTensor):\n",
    "        image = Image.fromarray(i)\n",
    "        image.save(os.path.join(path, str(c)+'.png'))\n",
    "    \n",
    "\n",
    "rgb_mapping = np.asarray([[43, 131, 186],[246,144, 83],[145, 203, 169], [226, 240, 177], [214, 25, 28]], dtype=np.uint8)\n",
    "#                           light blue  ,    Orange   ,  light green  , greenish yellow,      red  \n",
    "#                              cloud    ,    Water    ,  Vegetation   ,   Aquaculture  ,     other\n",
    "\n",
    "def color_map_from_classes_to_RGB(rgb_mapping, labels_tensor):\n",
    "    #input: [no. data, width, heigth]\n",
    "    #output: [no. data, width, height, RGB]\n",
    "    old_shape = labels_tensor.shape\n",
    "    labels_vector = np.reshape(labels_tensor, -1)\n",
    "\n",
    "    temp = np.zeros(labels_vector.shape + (3,))\n",
    "    for i,v in enumerate(labels_vector):\n",
    "        temp[i] = rgb_mapping[v-1]\n",
    "    temp = np.reshape(temp, old_shape + (3,))\n",
    "    rs = temp.astype(np.uint8)\n",
    "    return rs\n",
    "\n",
    "def plot_class(img):\n",
    "    plt.figure(figsize=(10,10))   \n",
    "    plt.imshow(img)\n",
    "    plt.title(\"tmp\")\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(6, 909, 879)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(87, 909, 879)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tiffPath = 'data\\Tiff_Image'\n",
    "inputTensor = write_tiff_data_into_tensor(tiffPath)\n",
    "inputTensor, oldShape = adding_synthetic_data_into_tensor(inputTensor, 0.15, 1)\n",
    "print(oldShape)\n",
    "inputTensor.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "MemoryError",
     "evalue": "Unable to allocate 670. MiB for an array with shape (58534275, 3) and data type int32",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mMemoryError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[1;32md:\\Study\\Thesis\\Bert_Interpolation\\playground.ipynb Cell 3'\u001b[0m in \u001b[0;36m<cell line: 12>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/Study/Thesis/Bert_Interpolation/playground.ipynb#ch0000002?line=9'>10</a>\u001b[0m                 TIEOFXTensor\u001b[39m.\u001b[39mappend(temp)\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/Study/Thesis/Bert_Interpolation/playground.ipynb#ch0000002?line=10'>11</a>\u001b[0m                 TIEOFYTensor\u001b[39m.\u001b[39mappend(value)\n\u001b[1;32m---> <a href='vscode-notebook-cell:/d%3A/Study/Thesis/Bert_Interpolation/playground.ipynb#ch0000002?line=11'>12</a>\u001b[0m TIEOFXTensor \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39;49masarray(TIEOFXTensor)\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/Study/Thesis/Bert_Interpolation/playground.ipynb#ch0000002?line=12'>13</a>\u001b[0m TIEOFYTensor \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39masarray(TIEOFYTensor)\n",
      "\u001b[1;31mMemoryError\u001b[0m: Unable to allocate 670. MiB for an array with shape (58534275, 3) and data type int32"
     ]
    }
   ],
   "source": [
    "TIEOFXTensor = []\n",
    "TIEOFYTensor = [] \n",
    "\n",
    "for time,tensor in enumerate(inputTensor):\n",
    "    for latitude,values in enumerate(tensor):\n",
    "        for longitude,value in enumerate(values):\n",
    "            if value != 1:\n",
    "                temp = [latitude, longitude, time]\n",
    "                temp = np.asarray(temp)\n",
    "                TIEOFXTensor.append(temp)\n",
    "                TIEOFYTensor.append(value)\n",
    "TIEOFXTensor = np.asarray(TIEOFXTensor)\n",
    "TIEOFYTensor = np.asarray(TIEOFYTensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Reconstruction:   0%|          | 0/300 [00:01<?, ?it/s, error=0.238, rel_error=0.238]2022-06-12 07:29:14.603 | INFO     | tieof.model.dineof3:_fit:108 - Error/Relative Error at iteraion 0: 0.23762852136828497, 0.23762852136828497\n",
      "Reconstruction:   0%|          | 1/300 [00:02<08:45,  1.76s/it, error=0.0875, rel_error=0.15]2022-06-12 07:29:15.807 | INFO     | tieof.model.dineof3:_fit:108 - Error/Relative Error at iteraion 1: 0.08746914850173905, 0.1501593728665459\n",
      "Reconstruction:   1%|          | 2/300 [00:04<07:06,  1.43s/it, error=0.0471, rel_error=0.0404]2022-06-12 07:29:16.961 | INFO     | tieof.model.dineof3:_fit:108 - Error/Relative Error at iteraion 2: 0.047090745065492684, 0.040378403436246366\n",
      "Reconstruction:   1%|          | 3/300 [00:05<06:27,  1.31s/it, error=0.0315, rel_error=0.0156]2022-06-12 07:29:18.130 | INFO     | tieof.model.dineof3:_fit:108 - Error/Relative Error at iteraion 3: 0.03146800989318178, 0.015622735172310907\n",
      "Reconstruction:   1%|▏         | 4/300 [00:06<06:10,  1.25s/it, error=0.0237, rel_error=0.00773]2022-06-12 07:29:19.570 | INFO     | tieof.model.dineof3:_fit:108 - Error/Relative Error at iteraion 4: 0.02374189122825156, 0.007726118664930216\n",
      "Reconstruction:   2%|▏         | 5/300 [00:07<06:29,  1.32s/it, error=0.0191, rel_error=0.00465]2022-06-12 07:29:20.806 | INFO     | tieof.model.dineof3:_fit:108 - Error/Relative Error at iteraion 5: 0.01909672211336272, 0.004645169114888843\n",
      "Reconstruction:   2%|▏         | 6/300 [00:09<06:19,  1.29s/it, error=0.0159, rel_error=0.0032] 2022-06-12 07:29:21.946 | INFO     | tieof.model.dineof3:_fit:108 - Error/Relative Error at iteraion 6: 0.015894922935336828, 0.003201799178025891\n",
      "Reconstruction:   2%|▏         | 7/300 [00:10<06:03,  1.24s/it, error=0.0135, rel_error=0.00241]2022-06-12 07:29:23.573 | INFO     | tieof.model.dineof3:_fit:108 - Error/Relative Error at iteraion 7: 0.013488517800550482, 0.0024064051347863456\n",
      "Reconstruction:   3%|▎         | 8/300 [00:11<06:38,  1.36s/it, error=0.0116, rel_error=0.00191]2022-06-12 07:29:24.636 | INFO     | tieof.model.dineof3:_fit:108 - Error/Relative Error at iteraion 8: 0.011581311399232342, 0.00190720640131814\n",
      "Reconstruction:   3%|▎         | 9/300 [00:12<06:09,  1.27s/it, error=0.01, rel_error=0.00156]  2022-06-12 07:29:25.649 | INFO     | tieof.model.dineof3:_fit:108 - Error/Relative Error at iteraion 9: 0.010019577333000601, 0.001561734066231741\n",
      "Reconstruction:   3%|▎         | 10/300 [00:13<05:45,  1.19s/it, error=0.00871, rel_error=0.0013]2022-06-12 07:29:26.638 | INFO     | tieof.model.dineof3:_fit:108 - Error/Relative Error at iteraion 10: 0.008714587059682739, 0.001304990273317862\n",
      "Reconstruction:   4%|▎         | 11/300 [00:14<05:26,  1.13s/it, error=0.00761, rel_error=0.0011]2022-06-12 07:29:27.542 | INFO     | tieof.model.dineof3:_fit:108 - Error/Relative Error at iteraion 11: 0.007613742953462093, 0.0011008441062206461\n",
      "Reconstruction:   4%|▍         | 12/300 [00:15<05:05,  1.06s/it, error=0.00667, rel_error=0.000943]2022-06-12 07:29:28.511 | INFO     | tieof.model.dineof3:_fit:108 - Error/Relative Error at iteraion 12: 0.006670461046535296, 0.0009432819069267965\n",
      "Reconstruction:   4%|▍         | 12/300 [00:15<06:16,  1.31s/it, error=0.00667, rel_error=0.000943]\n"
     ]
    }
   ],
   "source": [
    "from tieof import model\n",
    "\n",
    "tensorShape = np.asarray([inputTensor.shape[1], inputTensor.shape[2], inputTensor.shape[0]])\n",
    "R = 5\n",
    "dineof3 = model.DINEOF3(R = R, tensor_shape=tensorShape, decomp_type='HOOI')\n",
    "dineof3.fit(X = TIEOFXTensor, y=TIEOFYTensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = 'data\\TIEOF_recon_set2'\n",
    "imageTensor =[] \n",
    "for i in range(dineof3.reconstructed_tensor.shape[2]):\n",
    "    tensor = dineof3.reconstructed_tensor[:,:,i]\n",
    "    tensor = np.rint(tensor)\n",
    "    tensor = tensor.astype(np.uint8)\n",
    "    tensor = np.clip(tensor, 2, 5)\n",
    "    image = color_map_from_classes_to_RGB(rgb_mapping, tensor)\n",
    "    imageTensor.append(image)\n",
    "imageTensor = np.asarray(imageTensor)\n",
    "write_tensor_into_images(path, imageTensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from numpy.random import default_rng\n",
    "import cv2\n",
    "import skimage\n",
    "\n",
    "def create_random_blob(matrix: np.ndarray):\n",
    "    rng = default_rng()\n",
    "    noise = rng.integers(0,255, matrix.shape, np.uint8, True)\n",
    "\n",
    "    blur = cv2.GaussianBlur(noise, (0,0), sigmaX=15, sigmaY=15, borderType = cv2.BORDER_DEFAULT)\n",
    "    strech = skimage.exposure.rescale_intensity(blur,  in_range = 'image', out_range = (0,255)).astype(np.uint8)\n",
    "\n",
    "    thresh = cv2.threshold(strech, 175,1, cv2.THRESH_BINARY)[1]\n",
    "\n",
    "    size = rng.integers(3, 5, 2, np.uint8, True)\n",
    "    #rectKernel = cv2.getStructuringElement(cv2.MORPH_RECT, size)\n",
    "    ellipKernel = cv2.getStructuringElement(cv2.MORPH_ELLIPSE, size)\n",
    "    #crossKernel = cv2.getStructuringElement(cv2.MORPH_CROSS, size)\n",
    "    # kernels = [rectKernel, ellipKernel]\n",
    "    # r1 = rng.integers(low=0, high=1, dtype=np.uint8, endpoint=True)\n",
    "    # r2 = rng.integers(low=0, high=1, dtype=np.uint8, endpoint=True)\n",
    "\n",
    "    result = cv2.morphologyEx(thresh, cv2.MORPH_OPEN, ellipKernel)\n",
    "    result = cv2.morphologyEx(result, cv2.MORPH_CLOSE, ellipKernel)\n",
    "    \n",
    "    return result\n",
    "\n",
    "def create_random_clouds(matrix: np.ndarray, min_percent, value):\n",
    "    w, h = matrix.shape\n",
    "    noise_matrix = np.copy(matrix)\n",
    "\n",
    "    indices = np.argwhere(noise_matrix == value)\n",
    "\n",
    "    current_percent = len(indices)/(w*h)\n",
    "    while current_percent < min_percent:\n",
    "        temp = create_random_blob(noise_matrix)\n",
    "        indices = np.argwhere(temp == value)\n",
    "        for i,j in indices:\n",
    "            noise_matrix[i,j] = value\n",
    "        indices = np.argwhere(noise_matrix == value)\n",
    "        current_percent = len(indices)/(w*h)\n",
    "    return noise_matrix\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "def adding_synthetic_data_into_tensor(inputTensor: np.ndarray, threshold, value):\n",
    "    realDataShape = inputTensor.shape\n",
    "    w = realDataShape[1]\n",
    "    h = realDataShape[2]\n",
    "    for image in inputTensor:\n",
    "        indices = np.argwhere(image == value)\n",
    "        current_percent = len(indices)/(w*h)\n",
    "        interval = (threshold - current_percent)/20\n",
    "        while current_percent < threshold:\n",
    "            current_percent += interval\n",
    "            imputed_matrix = create_random_clouds(image, current_percent, value)\n",
    "            imputed_matrix = np.expand_dims(imputed_matrix, axis=0)\n",
    "            inputTensor = np.append(inputTensor, imputed_matrix, axis=0)\n",
    "    return inputTensor, realDataShape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "svdDataPath = 'data/funk_svd_format_data/real_and_synthetic_data'\n",
    "write_tensor_into_funksvd_format(inputTensor, svdDataPath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def write_tensor_into_funksvd_format(inputTensor: np.ndarray, path):\n",
    "    inputTensor = np.expand_dims(inputTensor, axis=-1)\n",
    "    oldShape = inputTensor.shape\n",
    "    inputTensor = np.reshape(inputTensor, (oldShape[0], oldShape[1]*oldShape[2], oldShape[3]))\n",
    "    with open(path, 'w') as f:\n",
    "        for user_id, img in enumerate(inputTensor):\n",
    "            for movie_id, _ in enumerate(inputTensor[user_id]):\n",
    "                for rating in inputTensor[user_id, movie_id]:\n",
    "                    if (rating != 1):\n",
    "                        f.write(\"{}\\t{}\\t{}\".format(user_id+1, movie_id+1, rating))\n",
    "                        f.write(\"\\n\")\n",
    "    inputTensor.reshape(oldShape)\n",
    "\n",
    "def tensor_reconstruction_using_funk_svd(inputTensor, realDataShape):\n",
    "  reconstructedTensors = []\n",
    "  for index, image in enumerate(inputTensor):\n",
    "    shape = image.shape\n",
    "    reconTensor = []\n",
    "    for i in range(1,shape[0]*shape[1]+1):\n",
    "      reconTensor.append(svd.predict_pair(index+1, i))\n",
    "    reconTensor = np.asarray(reconTensor)\n",
    "    reconTensor = np.rint(reconTensor)\n",
    "    reconTensor = reconTensor.astype(np.uint8)\n",
    "    reconTensor = np.reshape(reconTensor, shape)\n",
    "    reconstructedTensors.append(reconTensor)\n",
    "  reconstructedTensors = np.asarray(reconstructedTensors)\n",
    "  return reconstructedTensors\n",
    "\n",
    "def read_txt_file_into_df(path):\n",
    "    names = ['u_id', 'i_id', 'rating']\n",
    "    dtype = {'u_id': np.uint32, 'i_id': np.uint32, 'rating': np.float64}\n",
    "    df = pd.read_csv(svdDataPath, names=names, dtype=dtype, sep='\\t')\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Read tiff data into Tensor\n",
    "tiffPath = 'data\\Tiff_Image'\n",
    "inputTensor = write_tiff_data_into_tensor(tiffPath)\n",
    "#inputTensor, oldShape = adding_synthetic_data_into_tensor(inputTensor, 0.15, 1) #add synthetic data into inputTensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "svdDataPath = 'data/funk_svd_format_data/temp'\n",
    "write_tensor_into_funksvd_format(inputTensor, svdDataPath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preprocessing data...\n",
      "\n",
      "Preprocessing data...\n",
      "\n",
      "Epoch 1/500  | val_loss: 0.96 - val_rmse: 0.98 - val_mae: 0.90 - took 48.7 sec\n",
      "Epoch 2/500  | val_loss: 0.28 - val_rmse: 0.53 - val_mae: 0.37 - took 45.0 sec\n",
      "Epoch 3/500  | val_loss: 0.21 - val_rmse: 0.46 - val_mae: 0.26 - took 44.8 sec\n",
      "Epoch 4/500  | val_loss: 0.21 - val_rmse: 0.45 - val_mae: 0.25 - took 44.1 sec\n",
      "Epoch 5/500  | val_loss: 0.20 - val_rmse: 0.45 - val_mae: 0.25 - took 48.1 sec\n",
      "Epoch 6/500  | val_loss: 0.20 - val_rmse: 0.45 - val_mae: 0.26 - took 47.4 sec\n",
      "Epoch 7/500  | val_loss: 0.19 - val_rmse: 0.43 - val_mae: 0.25 - took 44.0 sec\n",
      "Epoch 8/500  | val_loss: 0.16 - val_rmse: 0.41 - val_mae: 0.25 - took 45.0 sec\n",
      "Epoch 9/500  | val_loss: 0.14 - val_rmse: 0.37 - val_mae: 0.22 - took 45.9 sec\n",
      "Epoch 10/500 | val_loss: 0.12 - val_rmse: 0.35 - val_mae: 0.20 - took 45.6 sec\n",
      "Epoch 11/500 | val_loss: 0.11 - val_rmse: 0.34 - val_mae: 0.18 - took 46.2 sec\n",
      "Epoch 12/500 | val_loss: 0.11 - val_rmse: 0.33 - val_mae: 0.17 - took 51.1 sec\n",
      "Epoch 13/500 | val_loss: 0.10 - val_rmse: 0.32 - val_mae: 0.17 - took 44.4 sec\n",
      "Epoch 14/500 | val_loss: 0.10 - val_rmse: 0.32 - val_mae: 0.16 - took 45.0 sec\n",
      "Epoch 15/500 | val_loss: 0.09 - val_rmse: 0.31 - val_mae: 0.16 - took 49.5 sec\n",
      "Epoch 16/500 | val_loss: 0.09 - val_rmse: 0.30 - val_mae: 0.16 - took 44.8 sec\n",
      "Epoch 17/500 | val_loss: 0.08 - val_rmse: 0.28 - val_mae: 0.16 - took 45.1 sec\n",
      "Epoch 18/500 | val_loss: 0.07 - val_rmse: 0.27 - val_mae: 0.16 - took 45.4 sec\n",
      "Epoch 19/500 | val_loss: 0.06 - val_rmse: 0.25 - val_mae: 0.15 - took 47.7 sec\n",
      "Epoch 20/500 | val_loss: 0.05 - val_rmse: 0.23 - val_mae: 0.14 - took 45.7 sec\n",
      "Epoch 21/500 | val_loss: 0.05 - val_rmse: 0.21 - val_mae: 0.13 - took 45.0 sec\n",
      "Epoch 22/500 | val_loss: 0.04 - val_rmse: 0.20 - val_mae: 0.11 - took 45.4 sec\n",
      "Epoch 23/500 | val_loss: 0.03 - val_rmse: 0.18 - val_mae: 0.10 - took 46.0 sec\n",
      "Epoch 24/500 | val_loss: 0.03 - val_rmse: 0.17 - val_mae: 0.09 - took 49.6 sec\n",
      "Epoch 25/500 | val_loss: 0.03 - val_rmse: 0.16 - val_mae: 0.08 - took 48.1 sec\n",
      "Epoch 26/500 | val_loss: 0.02 - val_rmse: 0.15 - val_mae: 0.07 - took 43.7 sec\n",
      "Epoch 27/500 | val_loss: 0.02 - val_rmse: 0.15 - val_mae: 0.07 - took 44.2 sec\n",
      "Epoch 28/500 | val_loss: 0.02 - val_rmse: 0.14 - val_mae: 0.06 - took 43.6 sec\n",
      "Epoch 29/500 | val_loss: 0.02 - val_rmse: 0.14 - val_mae: 0.06 - took 47.8 sec\n",
      "Epoch 30/500 | val_loss: 0.02 - val_rmse: 0.14 - val_mae: 0.05 - took 46.6 sec\n",
      "Epoch 31/500 | val_loss: 0.02 - val_rmse: 0.14 - val_mae: 0.05 - took 41.7 sec\n",
      "Epoch 32/500 | val_loss: 0.02 - val_rmse: 0.13 - val_mae: 0.04 - took 39.3 sec\n",
      "Epoch 33/500 | val_loss: 0.02 - val_rmse: 0.13 - val_mae: 0.04 - took 38.5 sec\n",
      "\n",
      "Training took 25 min and 33 sec\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<funk_svd.svd.SVD at 0x17a39860400>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from funk_svd import SVD\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "#Reading data into data frame \n",
    "svdDataPath = 'data/funk_svd_format_data/real_and_synthetic_data'\n",
    "df = read_txt_file_into_df(path)\n",
    "\n",
    "train = df.sample(frac=0.8, random_state = 7)\n",
    "val = df.drop(train.index.tolist()).sample(frac=0.5, random_state=8)\n",
    "test = df.drop(train.index.tolist()).drop(val.index.tolist())\n",
    "\n",
    "svd = SVD(lr=0.001, reg=0.001, n_epochs=500, n_factors=100, early_stopping=True, shuffle=True, min_rating=2, max_rating=5)\n",
    "\n",
    "svd.fit(X=train, X_val=val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "oldShape = inputTensor.shape\n",
    "temp = []\n",
    "\n",
    "for i in range(1,oldShape[1]*oldShape[2]+1):\n",
    "    temp.append(svd.predict_pair(6,i))\n",
    "temp = np.asarray(temp)\n",
    "temp = np.rint(temp)\n",
    "temp = temp.astype(np.uint8)\n",
    "rs = np.reshape(temp, (oldShape[1],oldShape[2]))"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "bd2bcd45e67a3cbce0b377fabe699339583fcde1ecb5341ffc733571be8b4199"
  },
  "kernelspec": {
   "display_name": "Python 3.9.1 ('venv': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
